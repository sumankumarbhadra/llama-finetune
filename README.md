# Llama-Finetune

A repository for fine-tuning Meta's Llama models.

## Overview

This repository contains notebooks for fine-tuning and using the Llama model. The project uses Unsloth for efficient fine-tuning and includes:

1. `Llama_3_2_3B_Instruct_Odia_Finetune.ipynb` - Notebook for fine-tuning the model
2. `Llama_3_2_3B_Instruct_Odia_inference.ipynb` - Notebook for inference with the fine-tuned model

## Model

The fine-tuned model is available on Hugging Face:
- Llama 3.2 3B Instruct model finetuned for Odia: [sumankumarbhadra/Llama-3.2-3B-Instruct-Odia](https://huggingface.co/sumankumarbhadra/Llama-3.2-3B-Instruct-Odia)


## Requirements

- Python 3.x
- PyTorch
- Transformers
- Unsloth
- CUDA-capable GPU (recommended)
